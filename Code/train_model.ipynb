{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model - Card Default Prediction \n",
    "\n",
    "In this notebook, a model will be created that predicts wheter the loan in question will default in the following 12 months, using the previously explored dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import Functions and Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plot\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split # to split the data into two parts\n",
    "from sklearn.linear_model import LogisticRegression # to apply the Logistic regression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import KFold # for cross validation\n",
    "from sklearn.model_selection import GridSearchCV # for tuning parameter\n",
    "from sklearn.model_selection import RandomizedSearchCV  # Randomized search on hyper parameters.\n",
    "from sklearn.preprocessing import StandardScaler # for normalization\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#Import functions from the DataProcessing.py file\n",
    "from DataProcessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dataset_original = \"../Dataset/exercise_syn_data_original.csv\"\n",
    "original_dataset = pd.read_csv(path_to_dataset_original, sep = \";\", decimal=\",\")\n",
    "seed = 42 # Seed for to unsure random processes are reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset = ReplaceNullValues(original_dataset) #Replace Unknown values (-1, -999) with NaNs\n",
    "processed_dataset = totalTransactionsColumn(processed_dataset) #Sum all columns of type \"amount_transaction_typeX\" to obtain the total amount spent \n",
    "processed_dataset = oneHotEncode(processed_dataset)  #One-hot encode the LivingStatus and EmploymentStatus columns\n",
    "processed_dataset = fillNaMean(processed_dataset) # Fill NaN values with the mean value for that specific feature\n",
    "processed_dataset = processed_dataset.drop(labels = ['EmploymentStatus', 'LivingStatus'], axis = 1) # columns no longer needed\n",
    "\n",
    "# Create new variable for all jobs, except the executive exmployee\n",
    "processed_dataset['Stable_Job'] = processed_dataset['Civil servants/governmental'] + processed_dataset['Employee'] + processed_dataset['Executive civil servant']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Divide Data into X and Y (features and target)\n",
    "- Split data into training data and testing data (80% / 20 %). Use stratify using target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = processed_dataset.drop('default', axis=1)  \n",
    "y = processed_dataset['default']\n",
    "\n",
    "X_train_, X_test_, y_train, y_test = train_test_split(X,y, test_size=0.2, stratify=y, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Two datasets are created, with diferent features. \n",
    "- The first features were selected with the findings from the DataExploration in mind. Features with most impact in the default probability and without unexpected behaviours were chosen.\n",
    "- In the second data set, the features from the first dataset were selected, plus the amount_transaction_type features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list1 = ['MonthlyIncome' ,'external_score_1','time_to_first_trx', 'Student', 'Retiree/pensioner',  'Stable_Job',  'Owner', 'total_amount_transaction']\n",
    "#'UnknownEmployment', 'Unemployed, 'Executive civil servant'\n",
    "column_list2 = ['MonthlyIncome' ,'external_score_1', 'external_score_2' ,'time_to_first_trx', 'Student', 'Retiree/pensioner',  'Stable_Job',  'Owner', 'total_amount_transaction'] + [ ('amount_transaction_type'+ str(x+1)) for x in range(16)] \n",
    "\n",
    "X_train1 = X_train_[column_list1]\n",
    "X_test1 = X_test_[column_list1]\n",
    "\n",
    "X_train2 = X_train_[column_list2]\n",
    "X_test2 = X_test_[column_list2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>external_score_1</th>\n",
       "      <th>time_to_first_trx</th>\n",
       "      <th>Student</th>\n",
       "      <th>Retiree/pensioner</th>\n",
       "      <th>Stable_Job</th>\n",
       "      <th>Owner</th>\n",
       "      <th>total_amount_transaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.00000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2108.685632</td>\n",
       "      <td>488.598754</td>\n",
       "      <td>89.32350</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.094250</td>\n",
       "      <td>0.436250</td>\n",
       "      <td>0.274000</td>\n",
       "      <td>-341.657325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>779.862204</td>\n",
       "      <td>73.954539</td>\n",
       "      <td>169.02661</td>\n",
       "      <td>0.179961</td>\n",
       "      <td>0.292213</td>\n",
       "      <td>0.495981</td>\n",
       "      <td>0.446065</td>\n",
       "      <td>574.800031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7905.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1500.000000</td>\n",
       "      <td>464.000000</td>\n",
       "      <td>25.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-446.452500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-108.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2500.000000</td>\n",
       "      <td>540.000000</td>\n",
       "      <td>71.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-14.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6001.000000</td>\n",
       "      <td>637.000000</td>\n",
       "      <td>1686.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MonthlyIncome  external_score_1  time_to_first_trx      Student  \\\n",
       "count    4000.000000       4000.000000         4000.00000  4000.000000   \n",
       "mean     2108.685632        488.598754           89.32350     0.033500   \n",
       "std       779.862204         73.954539          169.02661     0.179961   \n",
       "min      1000.000000        250.000000            9.00000     0.000000   \n",
       "25%      1500.000000        464.000000           25.00000     0.000000   \n",
       "50%      2000.000000        499.000000           39.00000     0.000000   \n",
       "75%      2500.000000        540.000000           71.00000     0.000000   \n",
       "max      6001.000000        637.000000         1686.00000     1.000000   \n",
       "\n",
       "       Retiree/pensioner   Stable_Job        Owner  total_amount_transaction  \n",
       "count        4000.000000  4000.000000  4000.000000               4000.000000  \n",
       "mean            0.094250     0.436250     0.274000               -341.657325  \n",
       "std             0.292213     0.495981     0.446065                574.800031  \n",
       "min             0.000000     0.000000     0.000000              -7905.120000  \n",
       "25%             0.000000     0.000000     0.000000               -446.452500  \n",
       "50%             0.000000     0.000000     0.000000               -108.095000  \n",
       "75%             0.000000     1.000000     1.000000                -14.775000  \n",
       "max             1.000000     1.000000     1.000000                  0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>external_score_1</th>\n",
       "      <th>time_to_first_trx</th>\n",
       "      <th>Student</th>\n",
       "      <th>Retiree/pensioner</th>\n",
       "      <th>Stable_Job</th>\n",
       "      <th>Owner</th>\n",
       "      <th>total_amount_transaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2140.801722</td>\n",
       "      <td>487.794684</td>\n",
       "      <td>85.341000</td>\n",
       "      <td>0.02900</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>0.443000</td>\n",
       "      <td>0.271000</td>\n",
       "      <td>-326.941850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>809.711998</td>\n",
       "      <td>74.119790</td>\n",
       "      <td>157.110396</td>\n",
       "      <td>0.16789</td>\n",
       "      <td>0.281976</td>\n",
       "      <td>0.496989</td>\n",
       "      <td>0.444699</td>\n",
       "      <td>575.456767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7115.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1500.000000</td>\n",
       "      <td>468.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-400.585000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>497.500000</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-125.155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2500.000000</td>\n",
       "      <td>539.000000</td>\n",
       "      <td>69.250000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-13.527500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6001.000000</td>\n",
       "      <td>637.000000</td>\n",
       "      <td>1384.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MonthlyIncome  external_score_1  time_to_first_trx     Student  \\\n",
       "count    1000.000000       1000.000000        1000.000000  1000.00000   \n",
       "mean     2140.801722        487.794684          85.341000     0.02900   \n",
       "std       809.711998         74.119790         157.110396     0.16789   \n",
       "min      1000.000000        253.000000          11.000000     0.00000   \n",
       "25%      1500.000000        468.000000          25.000000     0.00000   \n",
       "50%      2000.000000        497.500000          38.500000     0.00000   \n",
       "75%      2500.000000        539.000000          69.250000     0.00000   \n",
       "max      6001.000000        637.000000        1384.000000     1.00000   \n",
       "\n",
       "       Retiree/pensioner   Stable_Job        Owner  total_amount_transaction  \n",
       "count        1000.000000  1000.000000  1000.000000               1000.000000  \n",
       "mean            0.087000     0.443000     0.271000               -326.941850  \n",
       "std             0.281976     0.496989     0.444699                575.456767  \n",
       "min             0.000000     0.000000     0.000000              -7115.580000  \n",
       "25%             0.000000     0.000000     0.000000               -400.585000  \n",
       "50%             0.000000     0.000000     0.000000               -125.155000  \n",
       "75%             0.000000     1.000000     1.000000                -13.527500  \n",
       "max             1.000000     1.000000     1.000000                  0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train1.describe())\n",
    "display(X_test1.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Oversampling: Defaults are a minority class in the dataset. If we wish to improve the model performance in this, oversampling techniques like SMOTE provide a way to increase the representation of default data.\n",
    "- A sampling strategy of 0.20 was used, increasing the representation of default data from 4.6 % to 20 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(sampling_strategy = 0.20, random_state=seed)\n",
    "X_res1, y_res1 = sm.fit_resample(X_train1, y_train)\n",
    "\n",
    "sm = SMOTE(sampling_strategy = 0.20, random_state=seed)\n",
    "X_res2, y_res2 = sm.fit_resample(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create the predicative model, considering the following:\n",
    "\n",
    "Models tested :\n",
    "- Decision Tree\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- XGB Classifier\n",
    "\n",
    "Datasets:\n",
    "- Dataset1 was used for the DecisionTree and Logistic Regression models, since these are more simple models.\n",
    "- Dataset2 was used for the Random Forest and the XGB Classifier. Because these models are more complex, they are able to handle better the high number of features given to the model.\n",
    "\n",
    "Model training\n",
    "- As mentioned before, data was split in train and test data. All models were trained in the training data and tested in the testing data.\n",
    "- On top of that, hyperparameter tuning was performed in the training data, in order to choose the most adequate hyperparameters for each model. Stratified K Fold strategy was used for this purpose, with 5 splits.\n",
    "\n",
    "Evaluation Metrics:\n",
    "- Since we are doing a classification task, it would be tempting to evalute models using the accuracy metric. However, in this situation, we are doing Imbalanced Classification. We will use the AUC-ROC metric, since it measures the ability of the model to distinguish between default or no-default loans.\n",
    "\n",
    "Model Parameters:\n",
    "- All models presented some level of overfitting to the data. Because of this, strong regularization parameters were used.\n",
    "- Despite we are oversampling default data, there is still some Imbalancing in the training data. Because of this, a higher class weight for the default class was used, so that the misclassification made in the minority class is more penalized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Decision Tree Classifier\n",
    "- Dataset1 was used\n",
    "- Grid Search method was used to search hyperparameters\n",
    "- ROC AUC achieved: 0.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n",
      "0.8463835429552475\n",
      "{'class_weight': {0: 1, 1: 10}, 'criterion': 'gini', 'max_depth': 5, 'max_features': 5, 'min_samples_leaf': 8}\n",
      "0.8344954881050041\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.64      0.78       954\n",
      "           1       0.11      0.93      0.20        46\n",
      "\n",
      "    accuracy                           0.65      1000\n",
      "   macro avg       0.55      0.79      0.49      1000\n",
      "weighted avg       0.95      0.65      0.75      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state= seed)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle= True, random_state= seed)\n",
    "\n",
    "param_grid = {\"max_depth\": [1,2 ,3, 4, 5],\n",
    "              \"max_features\": [1,3 ,5],\n",
    "              \"min_samples_leaf\": [3, 5 , 8, 10],\n",
    "              \"criterion\": ['gini', 'entropy'],\n",
    "              \"class_weight\" : [{0:1, 1:5}, {0:1, 1:10}, {0:1, 1:25}]\n",
    "             \n",
    "              }\n",
    "\n",
    "best_model = GridSearchCV(estimator= model, param_grid= param_grid, \n",
    "                         cv= skf, verbose= True, n_jobs= -1, scoring = 'roc_auc')\n",
    "\n",
    "best_model.fit(X_res1, y_res1)\n",
    "print(best_model.best_score_)\n",
    "print(best_model.best_params_)\n",
    "\n",
    "y_pred_prob = best_model.predict_proba(X_test1)\n",
    "print(sklearn.metrics.roc_auc_score(y_test, y_pred_prob[:,1] ))\n",
    "\n",
    "y_pred = best_model.predict(X_test1)\n",
    "print(classification_report(y_test, y_pred ))\n",
    "\n",
    "#{'class_weight': {0: 1, 1: 10}, 'criterion': 'gini', 'max_depth': 5, 'max_features': 5, 'min_samples_leaf': 8}\n",
    "#ROC AUC: 0.8344954881050041"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Logistic Regression\n",
    "- Dataset1 was used\n",
    "- Grid Search method was used to search hyperparameters\n",
    "- ROC AUC achieved: 0.79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8361232727438311\n",
      "{'C': 1.389495494373136, 'class_weight': 'balanced', 'solver': 'liblinear'}\n",
      "0.7884878315559202\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.71      0.83       954\n",
      "           1       0.11      0.76      0.20        46\n",
      "\n",
      "    accuracy                           0.71      1000\n",
      "   macro avg       0.55      0.74      0.51      1000\n",
      "weighted avg       0.94      0.71      0.80      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LRModel = LogisticRegression(random_state=seed)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle= True, random_state= seed)\n",
    "\n",
    "param_grid = {'C': np.logspace(-5, 3, 15), \n",
    "              'solver': ['liblinear', 'newton-cg'],\n",
    "              \"class_weight\" : ['balanced']\n",
    "             }\n",
    "\n",
    "best_model = GridSearchCV(estimator= LRModel, param_grid= param_grid, \n",
    "                         cv= skf, verbose= False, n_jobs= -1, scoring = 'roc_auc')\n",
    "\n",
    "best_model.fit(X_res1, y_res1)\n",
    "print(best_model.best_score_)\n",
    "print(best_model.best_params_)\n",
    "\n",
    "y_pred_prob = best_model.predict_proba(X_test1)\n",
    "print(sklearn.metrics.roc_auc_score(y_test, y_pred_prob[:,1] ))\n",
    "\n",
    "y_pred = best_model.predict(X_test1)\n",
    "print(classification_report(y_test, y_pred ))\n",
    "\n",
    "#{'C': 1.389495494373136, 'class_weight': 'balanced', 'solver': 'liblinear'}\n",
    "#ROC AUC: 0.79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Random Forest Classifier\n",
    "- Dataset2 was used\n",
    "- Randomized Search method was used to search hyperparameters\n",
    "- ROC AUC achieved: 0.878"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "0.9305064863544\n",
      "{'n_estimators': 40, 'min_samples_leaf': 10, 'max_features': 7, 'max_depth': 6, 'criterion': 'gini'}\n",
      "0.877768662838392\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.90       954\n",
      "           1       0.18      0.76      0.29        46\n",
      "\n",
      "    accuracy                           0.83      1000\n",
      "   macro avg       0.58      0.80      0.59      1000\n",
      "weighted avg       0.95      0.83      0.87      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state = seed, class_weight = 'balanced')\n",
    "skf = StratifiedKFold(n_splits=5, shuffle= True, random_state= seed)\n",
    "\n",
    "param_grid = {'n_estimators': [20, 30, 40, 60],\n",
    "               \"max_features\": [2,3,4,5, 6, 7],\n",
    "               'max_depth': [1,2,3,4, 5, 6, 7],\n",
    "               \"min_samples_leaf\": [ 5, 10, 20 , 30 ],\n",
    "               \"criterion\": [ \"entropy\", \"gini\"] ,}\n",
    "\n",
    "best_model = RandomizedSearchCV(estimator= model, param_distributions= param_grid, cv= skf, verbose= True, n_jobs= -1, scoring = 'roc_auc', random_state=seed)\n",
    "\n",
    "best_model.fit(X_res2, y_res2)\n",
    "print(best_model.best_score_)\n",
    "print(best_model.best_params_)\n",
    "\n",
    "y_pred_prob = best_model.predict_proba(X_test2)\n",
    "print(sklearn.metrics.roc_auc_score(y_test, y_pred_prob[:,1] ))\n",
    "\n",
    "y_pred = best_model.predict(X_test2)\n",
    "print(classification_report(y_test, y_pred ))\n",
    "\n",
    "\n",
    "#{'n_estimators': 40, 'min_samples_leaf': 10, 'max_features': 7, 'max_depth': 6, 'criterion': 'gini'}\n",
    "#Score: 0.877"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 XGB Classifier\n",
    "- Dataset2 was used\n",
    "- Randomized Search method was used to search hyperparameters\n",
    "- ROC AUC achieved: 0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "0.9493388253418219\n",
      "{'reg_lambda': 10, 'reg_alpha': 1, 'n_estimators': 40, 'max_depth': 10, 'learning_rate': 0.1, 'gamma': 20}\n",
      "0.8800246103363413\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92       954\n",
      "           1       0.17      0.57      0.27        46\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.58      0.72      0.59      1000\n",
      "weighted avg       0.94      0.86      0.89      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(random_state = seed, scale_pos_weight =  5)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle= True, random_state= seed)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [ 20, 30 , 40 ],\n",
    "    'learning_rate': [0.01 , 0.05, 0.1 ],\n",
    "    'max_depth' : [3, 5, 7, 10, 20],\n",
    "    'gamma': [20 , 30, 50],\n",
    "    'reg_alpha': [1, 5, 10],\n",
    "    'reg_lambda': [5, 10],\n",
    "}\n",
    "\n",
    "#best_model = GridSearchCV(estimator= model, param_grid= param_grid, cv= skf, verbose= True, n_jobs= -1, scoring = 'roc_auc')\n",
    "best_model = RandomizedSearchCV(estimator= model, param_distributions= param_grid, cv= skf, verbose= True, n_jobs= -1, scoring = 'roc_auc', random_state=seed)\n",
    "\n",
    "best_model.fit(X_res2, y_res2)\n",
    "print(best_model.best_score_)\n",
    "print(best_model.best_params_)\n",
    "\n",
    "y_pred_prob = best_model.predict_proba(X_test2)\n",
    "print(sklearn.metrics.roc_auc_score(y_test, y_pred_prob[:,1] ))\n",
    "\n",
    "y_pred = best_model.predict(X_test2)\n",
    "print(classification_report(y_test, y_pred ))\n",
    "\n",
    "#best : {'reg_lambda': 10, 'reg_alpha': 1, 'n_estimators': 40, 'max_depth': 10, 'learning_rate': 0.1, 'gamma': 20}\n",
    "# ROC: 0.88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Choice\n",
    "\n",
    "The XGBoost classifier is the model chosen for loan default prediction. We use the power of Gradient Boosting to create this model, with strong regularization parameters. Model was trained in data which was oversampled in the default loan data. Higher class weights values for the default class were used, so that the misclassification made in the minority class is more penalized.\n",
    "\n",
    "Here are the characteristics of this model\n",
    "\n",
    "Model features:\n",
    "-  'MonthlyIncome' ,'external_score_1', 'external_score_2' ,'time_to_first_trx', 'Student', 'Retiree/pensioner',  'Stable_Job',  'Owner', 'total_amount_transaction', 'amount_transaction_typeX'\n",
    "\n",
    "Model Hyperparameters:\n",
    "- 'reg_lambda': 10, 'reg_alpha': 1, 'n_estimators': 40, 'max_depth': 10, 'learning_rate': 0.1, 'gamma': 20, 'scale_pos_weight' =  5\n",
    "\n",
    "Evalutation Metrics:\n",
    "- Train ROC AUC: 0.95\n",
    "- Test ROC AOC: 0.88\n",
    "\n",
    "Classification Report:\n",
    "\n",
    "                       precision recall   f1-score  count\n",
    "\n",
    "         0   0         0.98      0.87      0.92       954\n",
    "         0   1         0.17      0.57      0.27        46\n",
    "\n",
    "         macro avg     0.58      0.72      0.59      1000\n",
    "    \n",
    "         weighted av   0.94      0.86      0.89      1000\n",
    "         \n",
    "Overall, a very good ROC AUC score was achieved. The model performs better in classifying non-defaults than default loans. It was also possible to achieve a precision of 99 %, which means that we can be very confident of the non-default predictions made by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8800246103363413\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = best_model.predict_proba(X_test2)\n",
    "print(sklearn.metrics.roc_auc_score(y_test, y_pred[:,1] ))\n",
    "\n",
    "\n",
    "fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, y_pred[:,1] )\n",
    "auc = sklearn.metrics.roc_auc_score(y_test, y_pred[:,1])\n",
    "pyplot.plot(fpr,tpr,label=\"data 1, auc=\"+str(round(auc, 2)))\n",
    "pyplot.xlabel('False Positive Rate') \n",
    "pyplot.ylabel('True Positive Rate') \n",
    "pyplot.legend(loc=4)\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b01290141e826cf031f509b3628650a0d6e1431c1574d8772f880d1116f687b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16 ('CreditCard')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
